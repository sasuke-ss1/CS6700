program: train_wb.py
method: bayes
name: "complete-sweep"
metric:
  name: Episodic reward
  goal: maximize
parameters:
    explore:
      values: [20000]
    gamma:
      values: [0.99]
    init_eps: 
      values: [0.1, 0.5, 0.01]
    fin_eps: 
      values: [0.001, 0.005, 0.0001]
    buffer_size:
      values: [10000,20000,50000]
    batch_size:
      values: [16]
    target_update_freq:
      values: [16]
    epochs:
      values: [500]
    max_time_steps:
      values: [500]
    warm_up_steps:
      values: [250]
    use_max:
      values: [True,False]
    hidden_size1:
      values: [32,64,128,256]
    hidden_size2:
      values: [32,64,128,256]
    activation:
      values: [Tanh, Sigmoid, ReLU]
    learning_rate:
      values: [0.0001, 0.0005, 0.001]
    shuffle:
      values: [True, False]